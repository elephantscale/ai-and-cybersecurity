# AI and Security

### References

* Generative AI Cybersecurity & Privacy for Leaders: A Primer
* https://www.coursera.org/learn/generative-ai-security-privacy/home/module/1

* Twitter security researchers to follow
    * Simon Willison @simonw
    * Pliny the Liberator @elder_plinius

* Prompt injection

* [DeepSeek for hackers](https://news.risky.biz/deepseek-is-a-win-for-chinese-hackers/)
* [DeepSeek is 100% hackable](https://blogs.cisco.com/security/evaluating-security-risk-in-deepseek-and-other-frontier-reasoning-models)
* [Importing Phantoms: Measuring LLM Package Hallucination Vulnerabilities](https://arxiv.org/abs/2501.19012)
* [HarmBench](https://www.harmbench.org/)

#### Required reading at WWT (WMWare)

* [AI's Best Friend ](https://www.amazon.com/Best-Friend-Robert-RSnake-Hansen/dp/B0CWKY91WM/)

#### Noma

* Secure Your Entire Data & AI Lifecycle
* [https://noma.security/](https://noma.security/)

#### AI Goat
https://orca.security/resources/blog/orca-ai-goat-open-source-environment-owasp-risks/

#### GenAI OWASP
https://genai.owasp.org/

#### Prompt engineering
* for prompt engineering defense, https://pangea.cloud/ had a good presentation at a recent conference.  They had categorized 170 types of attacks
* Paul Baclace:	Preventing system prompt leakage can be accomplished by examining generated text and simply searching for the system prompt (perhaps edit distance to account for different formatting).
* 
